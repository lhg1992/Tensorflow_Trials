{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyResNetforCifar10_Tensorflow.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNPSEtS1wcC53RCu8pCq0SC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhg1992/Tensorflow_Trials/blob/main/MyResNetforCifar10_Tensorflow_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJRwZoVmlVP9"
      },
      "source": [
        "# ReadMe\n",
        "\n",
        "The augment dataset can't train up directly.\n",
        "<br>However, it can be used after training the original dataset, and boost val_acc from 81% to 91%!\n",
        "Strange! (sn=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odpY1zi0oLuS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6zOp4keRIeu"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_ffGRKQdcOn",
        "outputId": "25f14436-05ad-4282-bb2d-4cfd8f2a4659"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from tensorflow.keras import datasets, layers, activations, models\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D,  Layer\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import ZeroPadding2D, Activation, Add\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomCrop, RandomFlip, RandomRotation\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import time\n",
        "# start_time = time.time()\n",
        "\n",
        "print(os.getcwd())\n",
        "# tf.random.set_seed(sn)\n",
        "sn=10"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPXzqC6ceSgm"
      },
      "source": [
        "# # detect and init the TPU\n",
        "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "\n",
        "# # instantiate a distribution strategy\n",
        "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK3ARZJqeCvF"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGJEZevxdmz0",
        "outputId": "ab298a81-cfb2-4ecd-8370-b09a59702f33"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Another Normalization for augmentation ??bad\n",
        "# train_images=(train_images-[0.4914, 0.4822, 0.4465])/np.array([0.2023, 0.1994, 0.2010])\n",
        "# test_images=(test_images-[0.4914, 0.4822, 0.4465])/np.array([0.2023, 0.1994, 0.2010])\n",
        "\n",
        "print('traindata shape:'+ str(train_images.shape))\n",
        "print('trainlabel shape:'+ str(train_labels.shape))\n",
        "print('testdata shape:'+ str(test_images.shape))\n",
        "\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "print(type(train_images))\n",
        "\n",
        "\n",
        "# Augmentation\n",
        "aug = ImageDataGenerator(horizontal_flip=True, width_shift_range=4,\n",
        "                             height_shift_range=4)\n",
        "aug.fit(train_images)\n",
        "train_dataset=aug.flow(train_images,train_labels,batch_size = 128)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.batch(128)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "traindata shape:(50000, 32, 32, 3)\n",
            "trainlabel shape:(50000, 1)\n",
            "testdata shape:(10000, 32, 32, 3)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lsRi6hHgSt9"
      },
      "source": [
        "## With TPU Compatibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz5xKWPDecKM"
      },
      "source": [
        "# train_images_pad = tf.keras.layers.ZeroPadding2D(padding=4)(train_images)\n",
        "# train_dataset = tf.data.Dataset.from_tensor_slices((train_images_pad, train_labels))\n",
        "# test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "# test_dataset = test_dataset.batch(128)\n",
        "\n",
        "# # sess = tf.compat.v1.Session()\n",
        "# def data_augment(image, label):        \n",
        "# #     image=tf.pad(image, [[4, 4], [4, 4]], \"CONSTANT\", 0) \n",
        "# # #     image = tf.keras.layers.ZeroPadding2D(padding=4)(image) # require  4D    \n",
        "#     image = tf.image.random_crop(image, train_images.shape[1:], seed=sn) #require pad first\n",
        "    \n",
        "#     image = tf.image.random_flip_left_right(image,seed=sn)\n",
        "# #     image = tf.keras.preprocessing.image.random_rotation(image.eval(session=sess), 20)# fail, also can't fit TPU\n",
        "# #     image = tf.image.random_flip_up_down(image)\n",
        "# #     image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
        "#     # image = tf.image.random_brightness(image, max_delta=.2) # shouldn't use,\n",
        "#     return image, label\n",
        "\n",
        "\n",
        "# train_dataset = train_dataset.map(data_augment)\n",
        "# # #train_dataset = train_dataset.repeat()\n",
        "# train_dataset = train_dataset.shuffle(2048, seed=sn)\n",
        "\n",
        "# #!!! this is a must!!!\n",
        "# train_dataset = train_dataset.batch(128) ### !!! very important!!! to match with the batch_size in model.fit\n",
        "\n",
        "# # train_dataset = train_dataset.cache()\n",
        "# train_dataset = train_dataset.prefetch(128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOl9nQZLgsLs"
      },
      "source": [
        "# ResNet Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNYvaUbhFSUm"
      },
      "source": [
        "## Function to build a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ge1EO2SFRUG"
      },
      "source": [
        "def BasicBlock(x, planes, stride=1):\n",
        "    global blockID, stage\n",
        "    expansion = 1\n",
        "    x_skip=x\n",
        "# def __init__(self, in_planes, planes, stride=1):\n",
        "#     super(BasicBlock, self).__init__()\n",
        "    # self.conv1 = nn.Conv2d(\n",
        "    #     in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    x=ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x=Conv2D(planes, kernel_size=3, strides=stride, use_bias=False, name=f'{stage}-{blockID}-Bconv1')(x)\n",
        "\n",
        "    # self.bn1 = nn.BatchNorm2d(planes)\n",
        "    x = BatchNormalization(name=f'{stage}-{blockID}-Bbn1')(x)\n",
        "    x = Activation(activations.relu)(x)\n",
        "\n",
        "    # self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "    #                        stride=1, padding=1, bias=False)\n",
        "    x = Conv2D(planes, kernel_size=3, strides=1,  #as stride and kernel_size are fix\n",
        "                padding=\"same\", use_bias=False, name=f'{stage}-{blockID}-Bconv2')(x)   #padding='same' e.q. =1\n",
        "\n",
        "    # self.bn2 = nn.BatchNorm2d(planes)\n",
        "    x = BatchNormalization(name=f'{stage}-{blockID}-Bbn2')(x)\n",
        "\n",
        "    # self.shortcut = nn.Sequential()\n",
        "\n",
        "    # if stride != 1 or in_planes != self.expansion*planes:\n",
        "    if stride != 1:    \n",
        "        # self.shortcut = nn.Sequential(\n",
        "        #     nn.Conv2d(in_planes, self.expansion*planes,\n",
        "        #               kernel_size=1, stride=stride, bias=False),\n",
        "        #     nn.BatchNorm2d(self.expansion*planes)\n",
        "        # )\n",
        "        x_skip = Conv2D(expansion*planes,kernel_size=1, strides=stride, \n",
        "                        use_bias=False, name=f'{stage}-{blockID}-Bconv3')(x_skip)\n",
        "        x_skip = BatchNormalization(name=f'{stage}-{blockID}-Bbn3')(x_skip)            \n",
        "        \n",
        "    x = Add()([x,x_skip])\n",
        "    # out = F.relu(out)\n",
        "    out = Activation(activations.relu)(x)\n",
        "    blockID=blockID+1\n",
        "    return out"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8lP_FK7HF99"
      },
      "source": [
        "def make_layer(x, block, planes, num_blocks, stride, expansion):\n",
        "    global stage, blockID\n",
        "    strides = [stride] + [1]*(num_blocks-1)\n",
        "    print(\"num of blocks [stride]:\" + str(strides))\n",
        "    for stride in strides:\n",
        "        x = block(x, planes, stride)\n",
        "        # in_planes = planes * expansion\n",
        "    stage=stage+1\n",
        "    blockID=1 # reset for next stage\n",
        "    return x\n",
        "\n",
        "def ResNet(block, num_blocks, num_classes=10, expansion=1):\n",
        "    global blockID, stage\n",
        "    blockID=1\n",
        "    stage=1\n",
        "    input_im = tf.keras.Input(shape=(train_images.shape[1], train_images.shape[2], train_images.shape[3]))\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=1, padding='same', use_bias=False) (input_im)\n",
        "\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(activations.relu)(x)\n",
        "\n",
        "    x = make_layer(x, block, 64, num_blocks[0], 1, expansion)\n",
        "    x = make_layer(x, block, 128, num_blocks[1], 2, expansion)\n",
        "    x = make_layer(x, block, 256, num_blocks[2], 2, expansion)\n",
        "    x = make_layer(x, block, 512, num_blocks[3], 2, expansion)\n",
        "    \n",
        "    x = AveragePooling2D(pool_size=4)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(num_classes)(x)\n",
        "\n",
        "    model = Model(inputs=input_im, outputs=x, name='Resnet')\n",
        "    return model\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIqrqo50PQ-S"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83nBYPPePlmq",
        "outputId": "7eddf76d-fc4c-4fde-b002-0876fd52ba0c"
      },
      "source": [
        "def resetLR(epoch, lr):\n",
        "    if lr < 1e-5:\n",
        "        lr = 1e-3\n",
        "\n",
        "    print('learn rate:' + str(lr))\n",
        "    return lr\n",
        "\n",
        "lrdecay1 = tf.keras.callbacks.LearningRateScheduler(resetLR) # learning rate decay\n",
        "lrdecay1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.LearningRateScheduler at 0x7f6bf0536a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ5eZL5DPaY6",
        "outputId": "b341a5a7-8b22-442e-edd7-6dd621bcca0c"
      },
      "source": [
        "from math import pi,cos\n",
        "PlateauStep_prev=0 \n",
        "IniLr=0.01 \n",
        "LrHist=np.array([])\n",
        "def decayed_learning_rate(step, lr): \n",
        "    global PlateauStep_prev, IniLr, LrHist\n",
        "    initial_learning_rate=IniLr\n",
        "    decay_steps=200\n",
        "    alpha=0\n",
        "    currentLr=lr\n",
        "    currentstep=step\n",
        "    \n",
        "    step = step - PlateauStep_prev\n",
        "    step = min(step, decay_steps)\n",
        "    cosine_decay = 0.5 * (1 + tf.cos(pi * step / decay_steps))\n",
        "    decayed = (1 - alpha) * cosine_decay + alpha \n",
        "    lr=initial_learning_rate * decayed\n",
        "    \n",
        "    if currentLr<lr*(0.5+0.2): # 0.5 is the factor of tf.keras.callbacks.ReduceLROnPlateau\n",
        "        PlateauStep_prev=currentstep\n",
        "        IniLr=currentLr\n",
        "        initial_learning_rate=IniLr\n",
        "        step = step - PlateauStep_prev\n",
        "        step = min(step, decay_steps)\n",
        "        cosine_decay = 0.5 * (1 + tf.cos(pi * step / decay_steps))\n",
        "        decayed = (1 - alpha) * cosine_decay + alpha \n",
        "        lr=initial_learning_rate * decayed\n",
        "        \n",
        "    print('learn rate:' + str(np.array(lr)))\n",
        "    LrHist=np.block([LrHist,lr])\n",
        "    return lr\n",
        "\n",
        "CBcosLRdecay = tf.keras.callbacks.LearningRateScheduler(decayed_learning_rate)\n",
        "CBcosLRdecay"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.LearningRateScheduler at 0x7f6bf0547310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKQlyPbZPWbK"
      },
      "source": [
        "# Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s9bev2GMj4u",
        "outputId": "ee1050ac-bce1-4dbe-af1a-1d48ae11edb4"
      },
      "source": [
        "mod = ResNet18()\n",
        "mod.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of blocks [stride]:[1, 1]\n",
            "num of blocks [stride]:[2, 1]\n",
            "num of blocks [stride]:[2, 1]\n",
            "num of blocks [stride]:[2, 1]\n",
            "Model: \"Resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 64)   1728        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 34, 34, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "1-1-Bconv1 (Conv2D)             (None, 32, 32, 64)   36864       zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "1-1-Bbn1 (BatchNormalization)   (None, 32, 32, 64)   256         1-1-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           1-1-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "1-1-Bconv2 (Conv2D)             (None, 32, 32, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "1-1-Bbn2 (BatchNormalization)   (None, 32, 32, 64)   256         1-1-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 64)   0           1-1-Bbn2[0][0]                   \n",
            "                                                                 activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 34, 34, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "1-2-Bconv1 (Conv2D)             (None, 32, 32, 64)   36864       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "1-2-Bbn1 (BatchNormalization)   (None, 32, 32, 64)   256         1-2-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           1-2-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "1-2-Bconv2 (Conv2D)             (None, 32, 32, 64)   36864       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "1-2-Bbn2 (BatchNormalization)   (None, 32, 32, 64)   256         1-2-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           1-2-Bbn2[0][0]                   \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 64)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bconv1 (Conv2D)             (None, 16, 16, 128)  73728       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bbn1 (BatchNormalization)   (None, 16, 16, 128)  512         2-1-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 128)  0           2-1-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bconv2 (Conv2D)             (None, 16, 16, 128)  147456      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bconv3 (Conv2D)             (None, 16, 16, 128)  8192        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bbn2 (BatchNormalization)   (None, 16, 16, 128)  512         2-1-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "2-1-Bbn3 (BatchNormalization)   (None, 16, 16, 128)  512         2-1-Bconv3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 16, 16, 128)  0           2-1-Bbn2[0][0]                   \n",
            "                                                                 2-1-Bbn3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 128)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 18, 18, 128)  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2-2-Bconv1 (Conv2D)             (None, 16, 16, 128)  147456      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "2-2-Bbn1 (BatchNormalization)   (None, 16, 16, 128)  512         2-2-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 128)  0           2-2-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "2-2-Bconv2 (Conv2D)             (None, 16, 16, 128)  147456      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "2-2-Bbn2 (BatchNormalization)   (None, 16, 16, 128)  512         2-2-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           2-2-Bbn2[0][0]                   \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 128)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 18, 18, 128)  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bconv1 (Conv2D)             (None, 8, 8, 256)    294912      zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bbn1 (BatchNormalization)   (None, 8, 8, 256)    1024        3-1-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           3-1-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bconv2 (Conv2D)             (None, 8, 8, 256)    589824      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bconv3 (Conv2D)             (None, 8, 8, 256)    32768       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bbn2 (BatchNormalization)   (None, 8, 8, 256)    1024        3-1-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "3-1-Bbn3 (BatchNormalization)   (None, 8, 8, 256)    1024        3-1-Bconv3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 256)    0           3-1-Bbn2[0][0]                   \n",
            "                                                                 3-1-Bbn3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 10, 10, 256)  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "3-2-Bconv1 (Conv2D)             (None, 8, 8, 256)    589824      zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "3-2-Bbn1 (BatchNormalization)   (None, 8, 8, 256)    1024        3-2-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 256)    0           3-2-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "3-2-Bconv2 (Conv2D)             (None, 8, 8, 256)    589824      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "3-2-Bbn2 (BatchNormalization)   (None, 8, 8, 256)    1024        3-2-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 256)    0           3-2-Bbn2[0][0]                   \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 256)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 10, 10, 256)  0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bconv1 (Conv2D)             (None, 4, 4, 512)    1179648     zero_padding2d_6[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bbn1 (BatchNormalization)   (None, 4, 4, 512)    2048        4-1-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 512)    0           4-1-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bconv2 (Conv2D)             (None, 4, 4, 512)    2359296     activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bconv3 (Conv2D)             (None, 4, 4, 512)    131072      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bbn2 (BatchNormalization)   (None, 4, 4, 512)    2048        4-1-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "4-1-Bbn3 (BatchNormalization)   (None, 4, 4, 512)    2048        4-1-Bconv3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           4-1-Bbn2[0][0]                   \n",
            "                                                                 4-1-Bbn3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 6, 6, 512)    0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "4-2-Bconv1 (Conv2D)             (None, 4, 4, 512)    2359296     zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "4-2-Bbn1 (BatchNormalization)   (None, 4, 4, 512)    2048        4-2-Bconv1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 512)    0           4-2-Bbn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "4-2-Bconv2 (Conv2D)             (None, 4, 4, 512)    2359296     activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "4-2-Bbn2 (BatchNormalization)   (None, 4, 4, 512)    2048        4-2-Bconv2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           4-2-Bbn2[0][0]                   \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 512)    0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 512)          0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           5130        flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 11,183,562\n",
            "Trainable params: 11,173,962\n",
            "Non-trainable params: 9,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5iqafqFNAGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de947c85-230c-479c-f95f-72805303235b"
      },
      "source": [
        "#use categorical_crossentropy since the label is one-hot encoded\n",
        "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
        "opt = SGD(momentum=0.9,decay = 1e-04) #\n",
        "\n",
        "mod = ResNet18()\n",
        "# # with tpu_strategy.scope():\n",
        "# model.compile(optimizer = opt,\n",
        "#               loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), # False if softmax.\n",
        "#               metrics=[\"accuracy\"]) \n",
        "\n",
        "# use SparseCategoricalCrossentropy if labels is not encoded\n",
        "mod.compile(optimizer = opt,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # use from_logits=True if no sotfmax\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of blocks [stride]:[1, 1]\n",
            "num of blocks [stride]:[2, 1]\n",
            "num of blocks [stride]:[2, 1]\n",
            "num of blocks [stride]:[2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "davixfelQAKC"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HWN9uQWsQE2s",
        "outputId": "03137453-c0d6-44bc-f880-a5b311d177fc"
      },
      "source": [
        "es = EarlyStopping(patience= 40, restore_best_weights=True, monitor=\"val_accuracy\", verbose=1)\n",
        "lrdecay2=tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=7, verbose=1,\n",
        "    mode='auto')\n",
        "#I did not use cross validation, so the validate performance is not accurate.\n",
        "# STEPS = len(X_train) / 128*2\n",
        "history = mod.fit(\n",
        "                    # x=train_images, y=train_labels,\n",
        "                    # batch_size = 128, \n",
        "                    train_dataset,  #optimal 128 for GPU \n",
        "                    epochs=300, \n",
        "                    # validation_data=(test_images, test_labels),\n",
        "                    validation_data=test_dataset,\n",
        "                    callbacks=[CBcosLRdecay,es]\n",
        "                    # callbacks=[lrdecay2,lrdecay1,es],\n",
        "                   )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "learn rate:0.01\n",
            "391/391 [==============================] - 48s 121ms/step - loss: 0.6483 - accuracy: 0.7971 - val_loss: 0.6629 - val_accuracy: 0.7788\n",
            "Epoch 2/300\n",
            "learn rate:0.009999383\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.4608 - accuracy: 0.8409 - val_loss: 0.7550 - val_accuracy: 0.7551\n",
            "Epoch 3/300\n",
            "learn rate:0.009997532\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.4125 - accuracy: 0.8557 - val_loss: 0.5070 - val_accuracy: 0.8282\n",
            "Epoch 4/300\n",
            "learn rate:0.009994449\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.3768 - accuracy: 0.8675 - val_loss: 0.6356 - val_accuracy: 0.7880\n",
            "Epoch 5/300\n",
            "learn rate:0.009990133\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.3471 - accuracy: 0.8787 - val_loss: 0.5437 - val_accuracy: 0.8203\n",
            "Epoch 6/300\n",
            "learn rate:0.009984586\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.3211 - accuracy: 0.8894 - val_loss: 0.5065 - val_accuracy: 0.8335\n",
            "Epoch 7/300\n",
            "learn rate:0.009977809\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.3009 - accuracy: 0.8946 - val_loss: 0.6348 - val_accuracy: 0.7960\n",
            "Epoch 8/300\n",
            "learn rate:0.009969804\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.2800 - accuracy: 0.9030 - val_loss: 0.5119 - val_accuracy: 0.8384\n",
            "Epoch 9/300\n",
            "learn rate:0.009960574\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.2597 - accuracy: 0.9092 - val_loss: 0.4927 - val_accuracy: 0.8412\n",
            "Epoch 10/300\n",
            "learn rate:0.009950118\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.2432 - accuracy: 0.9161 - val_loss: 0.4817 - val_accuracy: 0.8449\n",
            "Epoch 11/300\n",
            "learn rate:0.009938441\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.2270 - accuracy: 0.9207 - val_loss: 0.4468 - val_accuracy: 0.8563\n",
            "Epoch 12/300\n",
            "learn rate:0.009925546\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.2119 - accuracy: 0.9266 - val_loss: 0.4500 - val_accuracy: 0.8590\n",
            "Epoch 13/300\n",
            "learn rate:0.009911436\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1952 - accuracy: 0.9325 - val_loss: 0.4853 - val_accuracy: 0.8541\n",
            "Epoch 14/300\n",
            "learn rate:0.009896114\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1843 - accuracy: 0.9352 - val_loss: 0.4425 - val_accuracy: 0.8655\n",
            "Epoch 15/300\n",
            "learn rate:0.0098795835\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1708 - accuracy: 0.9413 - val_loss: 0.4144 - val_accuracy: 0.8714\n",
            "Epoch 16/300\n",
            "learn rate:0.009861849\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.4363 - val_accuracy: 0.8689\n",
            "Epoch 17/300\n",
            "learn rate:0.009842915\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1499 - accuracy: 0.9480 - val_loss: 0.4122 - val_accuracy: 0.8763\n",
            "Epoch 18/300\n",
            "learn rate:0.009822787\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1450 - accuracy: 0.9485 - val_loss: 0.4166 - val_accuracy: 0.8775\n",
            "Epoch 19/300\n",
            "learn rate:0.009801469\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1316 - accuracy: 0.9553 - val_loss: 0.4789 - val_accuracy: 0.8631\n",
            "Epoch 20/300\n",
            "learn rate:0.009778965\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1256 - accuracy: 0.9560 - val_loss: 0.5181 - val_accuracy: 0.8595\n",
            "Epoch 21/300\n",
            "learn rate:0.009755282\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1228 - accuracy: 0.9581 - val_loss: 0.5436 - val_accuracy: 0.8523\n",
            "Epoch 22/300\n",
            "learn rate:0.009730427\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1092 - accuracy: 0.9620 - val_loss: 0.6380 - val_accuracy: 0.8395\n",
            "Epoch 23/300\n",
            "learn rate:0.009704404\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.1051 - accuracy: 0.9632 - val_loss: 0.4594 - val_accuracy: 0.8722\n",
            "Epoch 24/300\n",
            "learn rate:0.00967722\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0937 - accuracy: 0.9671 - val_loss: 0.4586 - val_accuracy: 0.8723\n",
            "Epoch 25/300\n",
            "learn rate:0.009648882\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0914 - accuracy: 0.9677 - val_loss: 0.4674 - val_accuracy: 0.8715\n",
            "Epoch 26/300\n",
            "learn rate:0.009619398\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0865 - accuracy: 0.9701 - val_loss: 0.5435 - val_accuracy: 0.8594\n",
            "Epoch 27/300\n",
            "learn rate:0.009588773\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 0.4443 - val_accuracy: 0.8777\n",
            "Epoch 28/300\n",
            "learn rate:0.009557016\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0761 - accuracy: 0.9732 - val_loss: 0.4561 - val_accuracy: 0.8768\n",
            "Epoch 29/300\n",
            "learn rate:0.009524135\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0760 - accuracy: 0.9742 - val_loss: 0.4417 - val_accuracy: 0.8812\n",
            "Epoch 30/300\n",
            "learn rate:0.009490138\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0686 - accuracy: 0.9766 - val_loss: 0.5298 - val_accuracy: 0.8676\n",
            "Epoch 31/300\n",
            "learn rate:0.009455032\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0640 - accuracy: 0.9780 - val_loss: 0.4432 - val_accuracy: 0.8809\n",
            "Epoch 32/300\n",
            "learn rate:0.009418828\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0591 - accuracy: 0.9799 - val_loss: 0.4509 - val_accuracy: 0.8826\n",
            "Epoch 33/300\n",
            "learn rate:0.009381534\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0572 - accuracy: 0.9804 - val_loss: 0.4656 - val_accuracy: 0.8828\n",
            "Epoch 34/300\n",
            "learn rate:0.0093431575\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.4571 - val_accuracy: 0.8816\n",
            "Epoch 35/300\n",
            "learn rate:0.00930371\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0501 - accuracy: 0.9834 - val_loss: 0.4620 - val_accuracy: 0.8856\n",
            "Epoch 36/300\n",
            "learn rate:0.009263201\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0501 - accuracy: 0.9826 - val_loss: 0.4839 - val_accuracy: 0.8829\n",
            "Epoch 37/300\n",
            "learn rate:0.0092216395\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0455 - accuracy: 0.9852 - val_loss: 0.4786 - val_accuracy: 0.8821\n",
            "Epoch 38/300\n",
            "learn rate:0.009179036\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0448 - accuracy: 0.9849 - val_loss: 0.4832 - val_accuracy: 0.8848\n",
            "Epoch 39/300\n",
            "learn rate:0.009135403\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.4505 - val_accuracy: 0.8903\n",
            "Epoch 40/300\n",
            "learn rate:0.009090749\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0404 - accuracy: 0.9862 - val_loss: 0.4693 - val_accuracy: 0.8847\n",
            "Epoch 41/300\n",
            "learn rate:0.009045085\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.5092 - val_accuracy: 0.8823\n",
            "Epoch 42/300\n",
            "learn rate:0.008998423\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.4780 - val_accuracy: 0.8890\n",
            "Epoch 43/300\n",
            "learn rate:0.0089507755\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.4577 - val_accuracy: 0.8896\n",
            "Epoch 44/300\n",
            "learn rate:0.008902152\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.4645 - val_accuracy: 0.8914\n",
            "Epoch 45/300\n",
            "learn rate:0.008852567\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 0.4846 - val_accuracy: 0.8911\n",
            "Epoch 46/300\n",
            "learn rate:0.00880203\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0270 - accuracy: 0.9912 - val_loss: 0.4619 - val_accuracy: 0.8936\n",
            "Epoch 47/300\n",
            "learn rate:0.008750555\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.4669 - val_accuracy: 0.8904\n",
            "Epoch 48/300\n",
            "learn rate:0.008698156\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.4716 - val_accuracy: 0.8875\n",
            "Epoch 49/300\n",
            "learn rate:0.008644843\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.4601 - val_accuracy: 0.8926\n",
            "Epoch 50/300\n",
            "learn rate:0.008590631\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.4475 - val_accuracy: 0.8949\n",
            "Epoch 51/300\n",
            "learn rate:0.008535534\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.4904 - val_accuracy: 0.8907\n",
            "Epoch 52/300\n",
            "learn rate:0.008479564\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.4556 - val_accuracy: 0.8980\n",
            "Epoch 53/300\n",
            "learn rate:0.008422736\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.4611 - val_accuracy: 0.8954\n",
            "Epoch 54/300\n",
            "learn rate:0.008365062\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.4617 - val_accuracy: 0.8958\n",
            "Epoch 55/300\n",
            "learn rate:0.008306559\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 0.4700 - val_accuracy: 0.8957\n",
            "Epoch 56/300\n",
            "learn rate:0.00824724\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.4853 - val_accuracy: 0.8946\n",
            "Epoch 57/300\n",
            "learn rate:0.00818712\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.4645 - val_accuracy: 0.8967\n",
            "Epoch 58/300\n",
            "learn rate:0.008126213\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.4571 - val_accuracy: 0.8978\n",
            "Epoch 59/300\n",
            "learn rate:0.008064535\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.4683 - val_accuracy: 0.8973\n",
            "Epoch 60/300\n",
            "learn rate:0.008002101\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.4771 - val_accuracy: 0.8969\n",
            "Epoch 61/300\n",
            "learn rate:0.007938926\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.4615 - val_accuracy: 0.8977\n",
            "Epoch 62/300\n",
            "learn rate:0.007875026\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 0.4681 - val_accuracy: 0.8968\n",
            "Epoch 63/300\n",
            "learn rate:0.0078104166\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.4686 - val_accuracy: 0.9008\n",
            "Epoch 64/300\n",
            "learn rate:0.0077451137\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 0.4553 - val_accuracy: 0.8987\n",
            "Epoch 65/300\n",
            "learn rate:0.007679133\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.4591 - val_accuracy: 0.9010\n",
            "Epoch 66/300\n",
            "learn rate:0.0076124924\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 0.4601 - val_accuracy: 0.9001\n",
            "Epoch 67/300\n",
            "learn rate:0.007545207\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.4551 - val_accuracy: 0.9009\n",
            "Epoch 68/300\n",
            "learn rate:0.0074772933\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.4578 - val_accuracy: 0.9009\n",
            "Epoch 69/300\n",
            "learn rate:0.0074087684\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.4735 - val_accuracy: 0.9010\n",
            "Epoch 70/300\n",
            "learn rate:0.007339649\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.4742 - val_accuracy: 0.8983\n",
            "Epoch 71/300\n",
            "learn rate:0.007269953\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.4573 - val_accuracy: 0.9015\n",
            "Epoch 72/300\n",
            "learn rate:0.0071996963\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.4568 - val_accuracy: 0.9048\n",
            "Epoch 73/300\n",
            "learn rate:0.0071288967\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.4569 - val_accuracy: 0.9012\n",
            "Epoch 74/300\n",
            "learn rate:0.007057572\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.4659 - val_accuracy: 0.9014\n",
            "Epoch 75/300\n",
            "learn rate:0.0069857393\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.4698 - val_accuracy: 0.9030\n",
            "Epoch 76/300\n",
            "learn rate:0.0069134175\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 0.4647 - val_accuracy: 0.9016\n",
            "Epoch 77/300\n",
            "learn rate:0.006840622\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.4511 - val_accuracy: 0.9032\n",
            "Epoch 78/300\n",
            "learn rate:0.006767374\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.4544 - val_accuracy: 0.9038\n",
            "Epoch 79/300\n",
            "learn rate:0.0066936896\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.4606 - val_accuracy: 0.9030\n",
            "Epoch 80/300\n",
            "learn rate:0.0066195866\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.4652 - val_accuracy: 0.9033\n",
            "Epoch 81/300\n",
            "learn rate:0.0065450845\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.4597 - val_accuracy: 0.9036\n",
            "Epoch 82/300\n",
            "learn rate:0.0064702015\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.4608 - val_accuracy: 0.9013\n",
            "Epoch 83/300\n",
            "learn rate:0.0063949553\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.4603 - val_accuracy: 0.9028\n",
            "Epoch 84/300\n",
            "learn rate:0.0063193645\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.4777 - val_accuracy: 0.9021\n",
            "Epoch 85/300\n",
            "learn rate:0.00624345\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.4606 - val_accuracy: 0.9043\n",
            "Epoch 86/300\n",
            "learn rate:0.006167227\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.4573 - val_accuracy: 0.9045\n",
            "Epoch 87/300\n",
            "learn rate:0.006090716\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.4718 - val_accuracy: 0.9031\n",
            "Epoch 88/300\n",
            "learn rate:0.006013937\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.4728 - val_accuracy: 0.9039\n",
            "Epoch 89/300\n",
            "learn rate:0.0059369067\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.4663 - val_accuracy: 0.9039\n",
            "Epoch 90/300\n",
            "learn rate:0.0058596455\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.4729 - val_accuracy: 0.9040\n",
            "Epoch 91/300\n",
            "learn rate:0.0057821725\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.4616 - val_accuracy: 0.9054\n",
            "Epoch 92/300\n",
            "learn rate:0.005704506\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.4643 - val_accuracy: 0.9039\n",
            "Epoch 93/300\n",
            "learn rate:0.005626666\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.4736 - val_accuracy: 0.9035\n",
            "Epoch 94/300\n",
            "learn rate:0.0055486714\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.4688 - val_accuracy: 0.9032\n",
            "Epoch 95/300\n",
            "learn rate:0.005470542\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.4664 - val_accuracy: 0.9047\n",
            "Epoch 96/300\n",
            "learn rate:0.005392295\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.4730 - val_accuracy: 0.9047\n",
            "Epoch 97/300\n",
            "learn rate:0.0053139525\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.4653 - val_accuracy: 0.9040\n",
            "Epoch 98/300\n",
            "learn rate:0.005235532\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4736 - val_accuracy: 0.9033\n",
            "Epoch 99/300\n",
            "learn rate:0.0051570535\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.4661 - val_accuracy: 0.9048\n",
            "Epoch 100/300\n",
            "learn rate:0.005078536\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.4726 - val_accuracy: 0.9051\n",
            "Epoch 101/300\n",
            "learn rate:0.0049999994\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.4747 - val_accuracy: 0.9042\n",
            "Epoch 102/300\n",
            "learn rate:0.004921463\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.4783 - val_accuracy: 0.9029\n",
            "Epoch 103/300\n",
            "learn rate:0.004842946\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.4703 - val_accuracy: 0.9043\n",
            "Epoch 104/300\n",
            "learn rate:0.004764468\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.4753 - val_accuracy: 0.9053\n",
            "Epoch 105/300\n",
            "learn rate:0.004686048\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.4715 - val_accuracy: 0.9057\n",
            "Epoch 106/300\n",
            "learn rate:0.004607705\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.4736 - val_accuracy: 0.9036\n",
            "Epoch 107/300\n",
            "learn rate:0.0045294585\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.4717 - val_accuracy: 0.9059\n",
            "Epoch 108/300\n",
            "learn rate:0.0044513284\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.4757 - val_accuracy: 0.9064\n",
            "Epoch 109/300\n",
            "learn rate:0.004373334\n",
            "391/391 [==============================] - 47s 120ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.4713 - val_accuracy: 0.9078\n",
            "Epoch 110/300\n",
            "learn rate:0.004295494\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.4724 - val_accuracy: 0.9064\n",
            "Epoch 111/300\n",
            "learn rate:0.0042178277\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.4757 - val_accuracy: 0.9061\n",
            "Epoch 112/300\n",
            "learn rate:0.004140354\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.4735 - val_accuracy: 0.9060\n",
            "Epoch 113/300\n",
            "learn rate:0.004063093\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4726 - val_accuracy: 0.9065\n",
            "Epoch 114/300\n",
            "learn rate:0.0039860634\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.4759 - val_accuracy: 0.9058\n",
            "Epoch 115/300\n",
            "learn rate:0.003909284\n",
            "364/391 [==========================>...] - ETA: 3s - loss: 0.0032 - accuracy: 0.9996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c023330600cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;31m# validation_data=(test_images, test_labels),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCBcosLRdecay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0;31m# callbacks=[lrdecay2,lrdecay1,es],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                    )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK3KJgnJF__v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
